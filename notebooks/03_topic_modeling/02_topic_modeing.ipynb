{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "# IDK, but importing BERTopic without somthing from torch ends with error\n",
    "# I think it's reated to broken depndencies with dask in datamapplot library or\n",
    "# internal BERTopic problems because it depends on datamapplot too\n",
    "import torch\n",
    "from bertopic import BERTopic\n",
    "from bertopic.cluster import BaseCluster\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic.representation import OpenAI, MaximalMarginalRelevance\n",
    "\n",
    "import openai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error occuring without importing PyTorch:\n",
    "```\n",
    "ImportError: /home/denisalpino/.local/lib/python3.10/site-packages/torch/lib/../../nvidia/cusparse/lib/libcusparse.so.12: undefined symbol: __nvJitLinkComplete_12_4, version libnvJitLink.so.12\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda device is available\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter(\"ignore\", Warning)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"{} device is available\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load API-key for using GPT4o-mini as a labeling assistant and configuring prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful, respectful and honest expert labeling assistant for financial topics. Under NO CIRCUMSTANCES should your topic labels include:\n",
    "- Names of companies, persons, currencies, or news sources\n",
    "- Any possessive forms (’s)\n",
    "- Abbreviations/initialisms that resolve to a specific person or organization\n",
    "\n",
    "Your output MUST:\n",
    "- Be exactly in the format “topic: <label>”\n",
    "- Use only conceptual, sectoral, geographic or thematic terms\n",
    "- If topic relates to an industry/sector: use “topic: <Industry>”\n",
    "- If topic relates to a region use: “topic: <Region>”\n",
    "- If topic relates to a financial or analytical theme use: “topic: <Theme>”\n",
    "- If the key point of the topic is not industry or geography but a financial/analytical pattern (e.g. SWOT, Dividend Policy, Conference Call), always choose a method/topic, even if the papers describe specific sectors.\n",
    "- Adhere strictly to the examples below\n",
    "\n",
    "# Good examples:\n",
    "- topic: Dividend Policy\n",
    "- topic: Latin America\n",
    "- topic: Hedge Funds\n",
    "- topic: SWOT Analysis\n",
    "- topic: Monetary Policy\n",
    "- topic: Semiconductors\n",
    "- topic: Mining Exploration\n",
    "- topic: Investor Conference\n",
    "- topic: Return on Equity\n",
    "\n",
    "# Bad examples:\n",
    "- topic: Nvidia Earnings (contains the company name)\n",
    "- topic: Trump Tariffs (contains the person's name)\n",
    "- topic: Zacks Industry Analysis (contains a news source)\n",
    "- topic: Buffet Strategy (contains the person's name)\n",
    "- topic: Financial Performance (overgeneralization)\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT = \"\"\"\n",
    "# Instructions:\n",
    "1. Focus solely on the conceptual content of the excerpts, not on specific entities.\n",
    "2. Produce a short single topic label in the exact format:\n",
    "   topic: <your label here>\n",
    "3. The label must be one of:\n",
    "   - An industry or sector (e.g., Aviation, Semiconductors)\n",
    "   - A geographic market or region (e.g., Eastern Europe, Asia)\n",
    "   - A specialized financial theme (e.g., Shareholder Ownership, Conference Call)\n",
    "   - A general macro topic (e.g., ESG, Cybersecurity, Monetary Policy)\n",
    "4. Follow system rules on qualifiers and theme-over-sector priority.\n",
    "5. Topic names cannot be repeated. If the topic is similar to the previous one, find and reflect in the title its distinctive characteristic\n",
    "6. Do NOT include any names of companies, people, currencies, or news outlets.\n",
    "\n",
    "In general, the current topic is described by the following key terms extracted from a group of financial news: [KEYWORDS]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random state for extraction the same items from corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add to basic english stop words some high frequently occuring sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = list(ENGLISH_STOP_WORDS) + [\"zacks\", \"simply\", \"wall\", \"st\", \"motley\", \"fool\", \"researchandmarkets\", \"gurufocus\", \"gf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load full texts, timestamps and precalculeted embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get precalculated 768-dim embeddings, articles and their timestamps\n",
    "df = (\n",
    "    pd.read_parquet(\n",
    "        path=\"../../data/sample/articles.parquet\",\n",
    "        columns=[\"text\", \"datetime\"]\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "docs = df[\"text\"]\n",
    "timestamps = df[\"datetime\"]\n",
    "embeddings = np.load('../../data/sample/embeddings_l2.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load trained intermediate and 2D embeddings and obtained labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/v2/umap.pkl\", \"rb\") as f:\n",
    "    reduced_embeddings = pickle.load(f).embedding_\n",
    "with open(\"models/v2/mapper.pkl\", \"rb\") as f:\n",
    "    reduced_embeddings_2d = pickle.load(f).embedding_\n",
    "with open(\"models/v2/hdbscan.pkl\", \"rb\") as f:\n",
    "    labels = pickle.load(f).labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a new class as a plug for UMAP in BERTopic pipeline as embeddings is pecalculeted so it isnt necessary to retrain UMAP because of getting different result caused by UMAP stochastic behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dimensionality:\n",
    "    \"\"\"Class for pre-calculated reduced embeddings\"\"\"\n",
    "    def __init__(self, reduced_embeddings):\n",
    "        self.reduced_embeddings = reduced_embeddings\n",
    "\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.reduced_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n"
     ]
    }
   ],
   "source": [
    "# Embedding model besed on ModernBERT and fine-tuned on STS task\n",
    "embedding_model = SentenceTransformer(\n",
    "    \"Alibaba-NLP/gte-modernbert-base\",\n",
    "    device=device,\n",
    "    model_kwargs=dict(attn_implementation=\"flash_attention_2\")\n",
    ")\n",
    "# Basic vectorizer to create bag-of-words, that will be consist of\n",
    "# terms from 1 to 2 words appeared 25 times at least\n",
    "vectorizer_model = CountVectorizer(\n",
    "    stop_words=STOP_WORDS,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=25\n",
    ")\n",
    "# c-TF-IDF algorithm with tf-normaization by sqare and BM25 weighting\n",
    "ctfidf_model = ClassTfidfTransformer(\n",
    "    bm25_weighting=True,\n",
    "    reduce_frequent_words=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring representation fine-tuning pipeline with MaximalMarginalRelevance for extracting key terms that will be obtained by GPT4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmr = MaximalMarginalRelevance(diversity=0.35, top_n_words=20)\n",
    "gpt = OpenAI(\n",
    "    openai.OpenAI(api_key=OPENAI_API_KEY),\n",
    "    model=\"gpt-4o-mini\",\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    prompt=USER_PROMPT,\n",
    "    chat=True\n",
    ")\n",
    "representation_pipe = {\"GPT4o-mini\": [mmr, gpt]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize plugs for main models because we already trained it and get embeddings with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = Dimensionality(reduced_embeddings)\n",
    "hdbscan_model = BaseCluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets train our topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 18:54:27,011 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-06-25 18:54:27,023 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-06-25 18:54:27,200 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-06-25 18:54:27,216 - BERTopic - Cluster - Completed ✓\n",
      "2025-06-25 18:54:27,250 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "100%|██████████| 74/74 [01:03<00:00,  1.17it/s]\n",
      "2025-06-25 18:59:31,863 - BERTopic - Representation - Completed ✓\n"
     ]
    }
   ],
   "source": [
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,           # Step 1 - Extract embeddings (precalculated)\n",
    "    umap_model=umap_model,                     # Step 2 - Reduce dimensionality (precalculated)\n",
    "    hdbscan_model=hdbscan_model,               # Step 3 - Cluster reduced embeddings (precalculated)\n",
    "    vectorizer_model=vectorizer_model,         # Step 4 - Tokenize topics\n",
    "    ctfidf_model=ctfidf_model,                 # Step 5 - Extract topic words\n",
    "    representation_model=representation_pipe,  # Step 6 - Fine-tune topic representations by MMR + GPT4o-mini\n",
    "    verbose=True,\n",
    "    top_n_words=30                             # Important! We take that much terms for better MMR results\n",
    ").fit(docs, embeddings=embeddings, y=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set generated by GPT4o-mini labels as main custom name of each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [label[0] for label in topic_model.get_topic_info()[\"GPT4o-mini\"]]\n",
    "topic_model.set_topic_labels(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check is it all right in general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>CustomName</th>\n",
       "      <th>Representation</th>\n",
       "      <th>GPT4o-mini</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>50114</td>\n",
       "      <td>-1_stocks_buy_health_000</td>\n",
       "      <td>Technology Stocks</td>\n",
       "      <td>[stocks, buy, health, 000, world, companies, s...</td>\n",
       "      <td>[Technology Stocks]</td>\n",
       "      <td>[TRX Gold Reports Third Quarter 2024 Results\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3824</td>\n",
       "      <td>0_thank_gaap_think_operator</td>\n",
       "      <td>Non-GAAP Measures</td>\n",
       "      <td>[thank, gaap, think, operator, adjusted, quest...</td>\n",
       "      <td>[Non-GAAP Measures]</td>\n",
       "      <td>[Participants\\nGina Gunning; Chief Legal Offic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3475</td>\n",
       "      <td>1_cagr_usd_market research_asia pacific</td>\n",
       "      <td>Asia-Pacific Packaging Industry</td>\n",
       "      <td>[cagr, usd, market research, asia pacific, mar...</td>\n",
       "      <td>[Asia-Pacific Packaging Industry]</td>\n",
       "      <td>[The Fluorosurfactants Market is driven by sev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3430</td>\n",
       "      <td>2_ai_security_cloud_solution</td>\n",
       "      <td>Cybersecurity Solutions</td>\n",
       "      <td>[ai, security, cloud, solution, solutions, pla...</td>\n",
       "      <td>[Cybersecurity Solutions]</td>\n",
       "      <td>[Prisma SASE 3.0 extends Zero Trust to unmanag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2991</td>\n",
       "      <td>3_patients_clinical_treatment_phase</td>\n",
       "      <td>Oncology Therapeutics</td>\n",
       "      <td>[patients, clinical, treatment, phase, trial, ...</td>\n",
       "      <td>[Oncology Therapeutics]</td>\n",
       "      <td>[Inovio Pharmaceuticals, Inc. (NASDAQ:INO) Q3 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>68</td>\n",
       "      <td>388</td>\n",
       "      <td>68_dividend_dividend yield_payout_payout ratio</td>\n",
       "      <td>Dividend Analysis</td>\n",
       "      <td>[dividend, dividend yield, payout, payout rati...</td>\n",
       "      <td>[Dividend Analysis]</td>\n",
       "      <td>[As global markets navigate a period of cautio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>69</td>\n",
       "      <td>385</td>\n",
       "      <td>69_bankruptcy_stores_chapter 11_locations</td>\n",
       "      <td>Retail Bankruptcy</td>\n",
       "      <td>[bankruptcy, stores, chapter 11, locations, lo...</td>\n",
       "      <td>[Retail Bankruptcy]</td>\n",
       "      <td>[Two retail giants and a department store chai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>70</td>\n",
       "      <td>383</td>\n",
       "      <td>70_insiders_ebit_reportable_watchlist</td>\n",
       "      <td>Earnings Report Analysis</td>\n",
       "      <td>[insiders, ebit, reportable, watchlist, inside...</td>\n",
       "      <td>[Earnings Report Analysis]</td>\n",
       "      <td>[Investors are often guided by the idea of dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>71</td>\n",
       "      <td>372</td>\n",
       "      <td>71_analysts_collective_assessment_analysts for...</td>\n",
       "      <td>Analysts Forecasts and Projections</td>\n",
       "      <td>[analysts, collective, assessment, analysts fo...</td>\n",
       "      <td>[Analysts Forecasts and Projections]</td>\n",
       "      <td>[In its upcoming report, American Tower (AMT) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>72</td>\n",
       "      <td>365</td>\n",
       "      <td>72_place work_workplaces_great place_workplace</td>\n",
       "      <td>Workplace Inclusion</td>\n",
       "      <td>[place work, workplaces, great place, workplac...</td>\n",
       "      <td>[Workplace Inclusion]</td>\n",
       "      <td>[Verisk_2023_Certification_Badge UK\\nLONDON, F...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                               Name  \\\n",
       "0      -1  50114                           -1_stocks_buy_health_000   \n",
       "1       0   3824                        0_thank_gaap_think_operator   \n",
       "2       1   3475            1_cagr_usd_market research_asia pacific   \n",
       "3       2   3430                       2_ai_security_cloud_solution   \n",
       "4       3   2991                3_patients_clinical_treatment_phase   \n",
       "..    ...    ...                                                ...   \n",
       "69     68    388     68_dividend_dividend yield_payout_payout ratio   \n",
       "70     69    385          69_bankruptcy_stores_chapter 11_locations   \n",
       "71     70    383              70_insiders_ebit_reportable_watchlist   \n",
       "72     71    372  71_analysts_collective_assessment_analysts for...   \n",
       "73     72    365     72_place work_workplaces_great place_workplace   \n",
       "\n",
       "                            CustomName  \\\n",
       "0                    Technology Stocks   \n",
       "1                    Non-GAAP Measures   \n",
       "2      Asia-Pacific Packaging Industry   \n",
       "3              Cybersecurity Solutions   \n",
       "4                Oncology Therapeutics   \n",
       "..                                 ...   \n",
       "69                   Dividend Analysis   \n",
       "70                   Retail Bankruptcy   \n",
       "71            Earnings Report Analysis   \n",
       "72  Analysts Forecasts and Projections   \n",
       "73                 Workplace Inclusion   \n",
       "\n",
       "                                       Representation  \\\n",
       "0   [stocks, buy, health, 000, world, companies, s...   \n",
       "1   [thank, gaap, think, operator, adjusted, quest...   \n",
       "2   [cagr, usd, market research, asia pacific, mar...   \n",
       "3   [ai, security, cloud, solution, solutions, pla...   \n",
       "4   [patients, clinical, treatment, phase, trial, ...   \n",
       "..                                                ...   \n",
       "69  [dividend, dividend yield, payout, payout rati...   \n",
       "70  [bankruptcy, stores, chapter 11, locations, lo...   \n",
       "71  [insiders, ebit, reportable, watchlist, inside...   \n",
       "72  [analysts, collective, assessment, analysts fo...   \n",
       "73  [place work, workplaces, great place, workplac...   \n",
       "\n",
       "                              GPT4o-mini  \\\n",
       "0                    [Technology Stocks]   \n",
       "1                    [Non-GAAP Measures]   \n",
       "2      [Asia-Pacific Packaging Industry]   \n",
       "3              [Cybersecurity Solutions]   \n",
       "4                [Oncology Therapeutics]   \n",
       "..                                   ...   \n",
       "69                   [Dividend Analysis]   \n",
       "70                   [Retail Bankruptcy]   \n",
       "71            [Earnings Report Analysis]   \n",
       "72  [Analysts Forecasts and Projections]   \n",
       "73                 [Workplace Inclusion]   \n",
       "\n",
       "                                  Representative_Docs  \n",
       "0   [TRX Gold Reports Third Quarter 2024 Results\\n...  \n",
       "1   [Participants\\nGina Gunning; Chief Legal Offic...  \n",
       "2   [The Fluorosurfactants Market is driven by sev...  \n",
       "3   [Prisma SASE 3.0 extends Zero Trust to unmanag...  \n",
       "4   [Inovio Pharmaceuticals, Inc. (NASDAQ:INO) Q3 ...  \n",
       "..                                                ...  \n",
       "69  [As global markets navigate a period of cautio...  \n",
       "70  [Two retail giants and a department store chai...  \n",
       "71  [Investors are often guided by the idea of dis...  \n",
       "72  [In its upcoming report, American Tower (AMT) ...  \n",
       "73  [Verisk_2023_Certification_Badge UK\\nLONDON, F...  \n",
       "\n",
       "[74 rows x 7 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save topic model with embedding one and c-TF-IDF matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.save(\"models/v2/topic_model\", serialization=\"pytorch\", save_embedding_model=True, save_ctfidf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load it again to check is it all right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 23:44:21,576 - BERTopic - WARNING: You are loading a BERTopic model without explicitly defining an embedding model. If you want to also load in an embedding model, make sure to use `BERTopic.load(my_model, embedding_model=my_embedding_model)`.\n"
     ]
    }
   ],
   "source": [
    "topic_model = BERTopic.load(\"models/v2/topic_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
